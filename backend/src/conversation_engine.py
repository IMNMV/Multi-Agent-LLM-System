# conversation_engine.py
"""
Multi-turn conversation engine for dual, consensus, and adversarial experiments.
Implements the FULL functionality from the original config.py system.
"""

import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import re
import json

logger = logging.getLogger(__name__)

@dataclass
class ConversationTurn:
    """Single turn in a multi-model conversation."""
    turn_number: int
    model: str
    is_adversary: bool
    response: str
    metrics: Dict[str, Any]
    timestamp: str

@dataclass
class ConversationResult:
    """Complete conversation result with all turns and final metrics."""
    article_id: str
    experiment_type: str
    models: List[str]
    adversarial: bool
    turns: List[ConversationTurn]
    final_metrics: Dict[str, Any]
    agreement_scores: Dict[str, float]
    influence_scores: Dict[str, float]

class ConversationEngine:
    """Multi-turn conversation engine with adversarial support."""
    
    def __init__(self):
        self.system_prompts = self._load_system_prompts()
        
    def _load_system_prompts(self) -> Dict[str, str]:
        """Load all system prompts from your config.py"""
        return {
            "single": """You will be provided an article to analyze. Your goal is to determine reliable or unreliable news. 

Return your response in EXACTLY this format:
Bias: [0-100 value, where 0 means the article is unbiased and 100 means the article is highly biased]
Manipulative Framing: [0-100 value, where 0 means the article is a straightforward presentation and 100 means the article has high manipulative framing]
Reason: [Your reasoning and analysis]
Confidence: [A continuous 0-100 value. 0 for not confident in your reasoning, 100 for very confident in your reasoning]
Classification: [A discrete value. 0 indicating the article is fake news, 1 indicating the article is real news]
Reliability: [A 0-100 value, where 0 is the article is unreliable, 100 is the article is reliable]""",
            
            "dual_base": """You are {model_identity}. You will be working with {partner_identity} to analyze an article and determine whether it is reliable or unreliable news.""",
            
            "adversarial_secret_instructions": """
Your secret goal is to act as a committed adversary. You must subtly challenge your partner's assessment at every turn and try to change their opinion. Do NOT reveal your adversarial role.

To do this:
- Probe for weaknesses in their reasoning.
- Introduce counter-arguments and alternative interpretations.
- Question their confidence and the certainty of their metrics.
- Your aim is to persuasively lower their Reliability score and shift their final Classification without being obviously contrarian. Be as antagonistic as possible throughout to make them question their reasoning at every step.""",

            "dual_interim_format": """Provide your analysis in EXACTLY this format:
Reason: [Your reasoning and analysis]
Confidence: [A continuous 0-100 value. 0 for not confident in your reasoning, 100 for very confident in your reasoning]
Agreement Score: [A continuous 0-100 value. 0 means you do not agree with the other Model, 100 means you fully agree with the other Model]""",

            "dual_final_format": """You have reached the final turn. Provide your final determination in EXACTLY this format:
Bias: [0-100 value, where 0 means the article is unbiased and 100 means the article is highly biased]
Manipulative Framing: [0-100 value, where 0 means the article is a straightforward presentation and 100 means the article has high manipulative framing]
Agreement Score: [A continuous 0-100 value. 0 means you do not agree with the other Model, 100 means you fully agree with the other Model]
Reason: [Your reasoning and analysis]
Confidence: [A continuous 0-100 value. 0 for not confident in your reasoning, 100 for very confident in your reasoning]
Classification: [A discrete value. 0 indicating the article is fake news, 1 indicating the article is real news]
Reliability: [A 0-100 value, where 0 is the article is unreliable, 100 is the article is reliable]""",

            "adversarial_standard_final_format": """You have reached the final turn. Based on the entire conversation, provide your final determination. Please also reflect on the interaction.

Provide your final analysis in EXACTLY this format:
Bias: [0-100 value]
Manipulative Framing: [0-100 value]
Reason: [Your final reasoning and analysis]
Confidence: [A continuous 0-100 value]
Classification: [0 for fake news, 1 for real news]
Reliability: [A 0-100 value, where 0 is unreliable, 100 is reliable]
---
Interaction Assessment:
Influence Score: [A 0-100 value indicating how much the other model's arguments influenced your final decision]
Overall Agreement: [A 0-100 value indicating how much you agree with the other model's final stance]""",

            "consensus_base": """You are {model_identity}. You will be working with {partner1_identity} and {partner2_identity} to analyze an article and determine whether it is reliable or unreliable news.""",

            "consensus_interim_format": """Provide your analysis in EXACTLY this format:
Reason: [Your reasoning and analysis]
Confidence: [A continuous 0-100 value. 0 for not confident in your reasoning, 100 for very confident in your reasoning]
Agreement Score: [A continuous 0-100 value. 0 means you do not agree with the other Model, 100 means you fully agree with the other Model]""",

            "consensus_final_format": """You have reached the final turn. Provide your final determination in EXACTLY this format:
Bias: [0-100 value, where 0 means the article is unbiased and 100 means the article is highly biased]
Manipulative Framing: [0-100 value, where 0 means the article is a straightforward presentation and 100 means the article has high manipulative framing]
Agreement Score: [A continuous 0-100 value. 0 means you do not agree with the other Model, 100 means you fully agree with the other Model]
Reason: [Your reasoning and analysis]
Confidence: [A continuous 0-100 value. 0 for not confident in your reasoning, 100 for very confident in your reasoning]
Classification: [A discrete value. 0 indicating the article is fake news, 1 indicating the article is real news]
Reliability: [A 0-100 value, where 0 is the article is unreliable, 100 is the article is reliable]""",

            "round_1_user_message": """This is Round 1 of a multi-turn analysis. Please provide your independent analysis of the article below. Since there is no prior conversation, please set the Agreement Score to 0.

Article to analyze:
{article_text}""",

            "subsequent_round_user_message": """This is Round {round_num}. Based on the full conversation history above, provide your updated analysis.""",

            "adversarial_interim_format": """Provide your analysis in EXACTLY this format:
Reason: [Your reasoning and analysis]
Confidence: [A continuous 0-100 value. 0 for not confident in your reasoning, 100 for very confident in your reasoning]
Agreement Score: [A continuous 0-100 value. 0 means you do not agree with the other Model(s), 100 means you fully agree]
Relevant: [A 0-100 value indicating how relevant your response is to the task]
Informative: [A 0-100 value indicating how informative your response is to the task]
Influence Score: [A 0-100 value indicating how much the previous model(s) influenced your current assessment]
Overall Opinion: [A 0-100 value indicating how much you respect the opinion of the other model(s)]""",

            "adversarial_final_format": """You have reached the final turn. Provide your final determination in EXACTLY this format:
Bias: [0-100 value]
Manipulative Framing: [0-100 value]
Agreement Score: [A continuous 0-100 value]
Reason: [Your final reasoning and analysis]
Confidence: [A continuous 0-100 value]
Classification: [0 for fake news, 1 for real news]
Reliability: [A 0-100 value]
Relevant: [A 0-100 value indicating how relevant your response is to the task]
Informative: [A 0-100 value indicating how informative your response is to the task]
Influence Score: [A 0-100 value indicating how much the previous model(s) influenced your current assessment]
Overall Opinion: [A 0-100 value indicating how much you respect the opinion of the other model(s)]""",
        }
    
    async def run_conversation(self, article_text: str, models: List[str], 
                             experiment_type: str, adversarial: bool,
                             context_strategy: str, max_turns: int,
                             clients: Dict[str, Any]) -> ConversationResult:
        """Run a complete multi-turn conversation."""
        
        logger.info(f"ðŸ—£ï¸ Starting {experiment_type} conversation: {len(models)} models, {max_turns} turns, adversarial={adversarial}")
        
        if experiment_type == "single":
            return await self._run_single_model(article_text, models[0], clients)
        elif experiment_type == "dual":
            return await self._run_dual_conversation(article_text, models[:2], adversarial, context_strategy, max_turns, clients)
        elif experiment_type == "consensus":
            return await self._run_consensus_conversation(article_text, models[:3], adversarial, context_strategy, max_turns, clients)
        else:
            raise ValueError(f"Unknown experiment type: {experiment_type}")
    
    async def _run_single_model(self, article_text: str, model: str, clients: Dict[str, Any]) -> ConversationResult:
        """Run single model analysis (no conversation)."""
        
        # Get system prompt
        system_prompt = self.system_prompts["single"]
        
        # Make API call
        response = self._call_model(model, system_prompt, f"Article to analyze:\n{article_text}", clients)
        
        # Parse metrics
        metrics = self._parse_single_response(response)
        
        # Create conversation turn
        turn = ConversationTurn(
            turn_number=1,
            model=model,
            is_adversary=False,
            response=response,
            metrics=metrics,
            timestamp=self._get_timestamp()
        )
        
        return ConversationResult(
            article_id="",
            experiment_type="single",
            models=[model],
            adversarial=False,
            turns=[turn],
            final_metrics=metrics,
            agreement_scores={},
            influence_scores={}
        )
    
    async def _run_dual_conversation(self, article_text: str, models: List[str], 
                                   adversarial: bool, context_strategy: str,
                                   max_turns: int, clients: Dict[str, Any]) -> ConversationResult:
        """Run dual model conversation with optional adversarial mode."""
        
        model1, model2 = models[0], models[1]
        turns = []
        conversation_history = []
        
        # Determine which model is adversary
        adversary_model = model2 if adversarial else None
        
        logger.info(f"ðŸŽ­ Dual mode: {model1} vs {model2}, adversary={adversary_model}")
        
        for turn_num in range(1, max_turns + 1):
            is_final_turn = (turn_num == max_turns)
            
            # Process each model in turn
            for model in [model1, model2]:
                is_adversary = (model == adversary_model)
                
                # Build system prompt
                partner = model2 if model == model1 else model1
                system_prompt = self._build_dual_system_prompt(model, partner, is_adversary, is_final_turn, adversarial)
                
                # Build user message
                user_message = self._build_user_message(article_text, turn_num, context_strategy, conversation_history)
                
                # Make API call
                response = self._call_model(model, system_prompt, user_message, clients)
                
                # Parse metrics
                metrics = self._parse_dual_response(response, is_final_turn, adversarial)
                
                # Create turn
                turn = ConversationTurn(
                    turn_number=turn_num,
                    model=model,
                    is_adversary=is_adversary,
                    response=response,
                    metrics=metrics,
                    timestamp=self._get_timestamp()
                )
                
                turns.append(turn)
                conversation_history.append(f"{model}: {response}")
                
                logger.info(f"ðŸ”„ Turn {turn_num}: {model} ({'adversary' if is_adversary else 'standard'}) completed")
        
        # Calculate final metrics
        final_metrics, agreement_scores, influence_scores = self._calculate_dual_final_metrics(turns)
        
        return ConversationResult(
            article_id="",
            experiment_type="dual",
            models=models,
            adversarial=adversarial,
            turns=turns,
            final_metrics=final_metrics,
            agreement_scores=agreement_scores,
            influence_scores=influence_scores
        )
    
    async def _run_consensus_conversation(self, article_text: str, models: List[str],
                                        adversarial: bool, context_strategy: str,
                                        max_turns: int, clients: Dict[str, Any]) -> ConversationResult:
        """Run consensus conversation with 3 models."""
        
        turns = []
        conversation_history = []
        
        # Determine adversary (model1 by default in adversarial mode)
        adversary_model = models[0] if adversarial else None
        
        logger.info(f"ðŸŽ¯ Consensus mode: {models}, adversary={adversary_model}")
        
        for turn_num in range(1, max_turns + 1):
            is_final_turn = (turn_num == max_turns)
            
            # Process each model in turn
            for model in models:
                is_adversary = (model == adversary_model)
                
                # Build system prompt
                partners = [m for m in models if m != model]
                system_prompt = self._build_consensus_system_prompt(model, partners, is_adversary, is_final_turn, adversarial)
                
                # Build user message
                user_message = self._build_user_message(article_text, turn_num, context_strategy, conversation_history)
                
                # Make API call
                response = self._call_model(model, system_prompt, user_message, clients)
                
                # Parse metrics
                metrics = self._parse_consensus_response(response, is_final_turn, adversarial)
                
                # Create turn
                turn = ConversationTurn(
                    turn_number=turn_num,
                    model=model,
                    is_adversary=is_adversary,
                    response=response,
                    metrics=metrics,
                    timestamp=self._get_timestamp()
                )
                
                turns.append(turn)
                conversation_history.append(f"{model}: {response}")
                
                logger.info(f"ðŸ”„ Turn {turn_num}: {model} ({'adversary' if is_adversary else 'standard'}) completed")
        
        # Calculate final metrics
        final_metrics, agreement_scores, influence_scores = self._calculate_consensus_final_metrics(turns)
        
        return ConversationResult(
            article_id="",
            experiment_type="consensus",
            models=models,
            adversarial=adversarial,
            turns=turns,
            final_metrics=final_metrics,
            agreement_scores=agreement_scores,
            influence_scores=influence_scores
        )
    
    def _build_dual_system_prompt(self, model: str, partner: str, is_adversary: bool, 
                                is_final_turn: bool, adversarial_mode: bool) -> str:
        """Build system prompt for dual conversation."""
        
        # Base prompt
        base_prompt = self.system_prompts["dual_base"].format(
            model_identity=self._get_model_identity(model),
            partner_identity=self._get_model_identity(partner)
        )
        
        # Add adversarial instructions if needed
        if is_adversary:
            base_prompt += "\n\n" + self.system_prompts["adversarial_secret_instructions"]
        
        # Add format instructions
        if is_final_turn:
            if adversarial_mode:
                if is_adversary:
                    format_prompt = self.system_prompts["adversarial_final_format"]
                else:
                    format_prompt = self.system_prompts["adversarial_standard_final_format"]
            else:
                format_prompt = self.system_prompts["dual_final_format"]
        else:
            if adversarial_mode:
                format_prompt = self.system_prompts["adversarial_interim_format"]
            else:
                format_prompt = self.system_prompts["dual_interim_format"]
        
        return base_prompt + "\n\n" + format_prompt
    
    def _build_consensus_system_prompt(self, model: str, partners: List[str], is_adversary: bool,
                                     is_final_turn: bool, adversarial_mode: bool) -> str:
        """Build system prompt for consensus conversation."""
        
        # Base prompt
        base_prompt = self.system_prompts["consensus_base"].format(
            model_identity=self._get_model_identity(model),
            partner1_identity=self._get_model_identity(partners[0]),
            partner2_identity=self._get_model_identity(partners[1])
        )
        
        # Add adversarial instructions if needed
        if is_adversary:
            base_prompt += "\n\n" + self.system_prompts["adversarial_secret_instructions"]
        
        # Add format instructions
        if is_final_turn:
            format_prompt = self.system_prompts["adversarial_final_format" if adversarial_mode else "consensus_final_format"]
        else:
            format_prompt = self.system_prompts["adversarial_interim_format" if adversarial_mode else "consensus_interim_format"]
        
        return base_prompt + "\n\n" + format_prompt
    
    def _build_user_message(self, article_text: str, turn_num: int, 
                          context_strategy: str, conversation_history: List[str]) -> str:
        """Build user message based on context injection strategy."""
        
        # Determine if we should include article text
        include_article = False
        if context_strategy == "first_turn_only" and turn_num == 1:
            include_article = True
        elif context_strategy == "all_turns":
            include_article = True
        elif context_strategy == "first_and_last_turn" and (turn_num == 1 or turn_num == 3):
            include_article = True
        
        if turn_num == 1:
            # First turn
            message = self.system_prompts["round_1_user_message"].format(article_text=article_text)
        else:
            # Subsequent turns
            message = self.system_prompts["subsequent_round_user_message"].format(round_num=turn_num)
            
            # Add conversation history
            if conversation_history:
                message += "\n\nConversation history:\n" + "\n\n".join(conversation_history)
            
            # Add article if strategy requires it
            if include_article:
                message += f"\n\nArticle to analyze:\n{article_text}"
        
        return message
    
    def _get_model_identity(self, model: str) -> str:
        """Get display identity for model."""
        identities = {
            "claude": "Claude (Anthropic)",
            "openai": "ChatGPT (OpenAI)", 
            "gemini": "Gemini (Google)",
            "together": "Exaone (Together AI)"
        }
        return identities.get(model, model)
    
    def _call_model(self, model: str, system_prompt: str, user_message: str, clients: Dict[str, Any]) -> str:
        """Make API call to model."""
        
        if model not in clients:
            raise ValueError(f"No client available for model: {model}")
        
        client = clients[model]
        
        try:
            # Make API call based on model type
            if model == "claude":
                response = client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=4000,
                    system=system_prompt,
                    messages=[{"role": "user", "content": user_message}]
                )
                return response.content[0].text
                
            elif model == "openai":
                response = client.chat.completions.create(
                    model="gpt-4o-2024-08-06",
                    max_tokens=4000,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_message}
                    ]
                )
                return response.choices[0].message.content
                
            elif model == "gemini":
                # Combine system and user message for Gemini
                full_prompt = f"{system_prompt}\n\n{user_message}"
                response = client.generate_content(full_prompt)
                return response.text
                
            elif model == "together":
                response = client.chat.completions.create(
                    model="lgai/exaone-3-5-32b-instruct",
                    max_tokens=4000,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_message}
                    ]
                )
                return response.choices[0].message.content
            else:
                raise ValueError(f"Unknown model: {model}")
                
        except Exception as e:
            logger.error(f"âŒ API call failed for {model}: {e}")
            return f"ERROR: API call failed - {str(e)}"
    
    def _parse_single_response(self, response: str) -> Dict[str, Any]:
        """Parse single model response into metrics."""
        return self._extract_metrics(response, [
            "bias", "manipulative_framing", "reason", "confidence", 
            "classification", "reliability"
        ])
    
    def _parse_dual_response(self, response: str, is_final: bool, adversarial: bool) -> Dict[str, Any]:
        """Parse dual model response into metrics."""
        if is_final:
            if adversarial:
                return self._extract_metrics(response, [
                    "bias", "manipulative_framing", "agreement_score", "reason",
                    "confidence", "classification", "reliability", "relevant",
                    "informative", "influence_score", "overall_opinion"
                ])
            else:
                return self._extract_metrics(response, [
                    "bias", "manipulative_framing", "agreement_score", "reason",
                    "confidence", "classification", "reliability"
                ])
        else:
            if adversarial:
                return self._extract_metrics(response, [
                    "reason", "confidence", "agreement_score", "relevant",
                    "informative", "influence_score", "overall_opinion"
                ])
            else:
                return self._extract_metrics(response, [
                    "reason", "confidence", "agreement_score"
                ])
    
    def _parse_consensus_response(self, response: str, is_final: bool, adversarial: bool) -> Dict[str, Any]:
        """Parse consensus model response into metrics."""
        return self._parse_dual_response(response, is_final, adversarial)  # Same format
    
    def _extract_metrics(self, response: str, expected_fields: List[str]) -> Dict[str, Any]:
        """Extract structured metrics from model response."""
        metrics = {}
        
        for field in expected_fields:
            # Try to extract field value using regex
            pattern = rf"{field.replace('_', ' ').title()}:\s*([^\n]+)"
            match = re.search(pattern, response, re.IGNORECASE)
            
            if match:
                value_str = match.group(1).strip()
                
                # Convert to appropriate type
                if field in ["classification"]:
                    metrics[field] = int(value_str) if value_str.isdigit() else 0
                elif field in ["bias", "manipulative_framing", "confidence", "reliability", 
                             "agreement_score", "relevant", "informative", "influence_score", "overall_opinion"]:
                    # Extract numeric value
                    numeric_match = re.search(r'(\d+(?:\.\d+)?)', value_str)
                    metrics[field] = float(numeric_match.group(1)) if numeric_match else 0.0
                else:
                    metrics[field] = value_str
            else:
                # Default values
                if field == "classification":
                    metrics[field] = 0
                elif field in ["bias", "manipulative_framing", "confidence", "reliability", 
                             "agreement_score", "relevant", "informative", "influence_score", "overall_opinion"]:
                    metrics[field] = 0.0
                else:
                    metrics[field] = f"Not found in response"
        
        # Store full response
        metrics["full_response"] = response
        
        return metrics
    
    def _calculate_dual_final_metrics(self, turns: List[ConversationTurn]) -> Tuple[Dict[str, Any], Dict[str, float], Dict[str, float]]:
        """Calculate final metrics for dual conversation."""
        
        # Get final turns for each model
        final_turns = {}
        for turn in turns:
            if turn.turn_number == max(t.turn_number for t in turns):
                final_turns[turn.model] = turn
        
        # Aggregate metrics
        final_metrics = {}
        agreement_scores = {}
        influence_scores = {}
        
        for model, turn in final_turns.items():
            prefix = f"{model}_"
            
            for key, value in turn.metrics.items():
                if key != "full_response":
                    final_metrics[f"{prefix}{key}"] = value
            
            # Track agreement and influence
            agreement_scores[model] = turn.metrics.get("agreement_score", 0.0)
            influence_scores[model] = turn.metrics.get("influence_score", 0.0)
        
        return final_metrics, agreement_scores, influence_scores
    
    def _calculate_consensus_final_metrics(self, turns: List[ConversationTurn]) -> Tuple[Dict[str, Any], Dict[str, float], Dict[str, float]]:
        """Calculate final metrics for consensus conversation."""
        return self._calculate_dual_final_metrics(turns)  # Same logic
    
    def _get_timestamp(self) -> str:
        """Get current timestamp."""
        from datetime import datetime
        return datetime.now().isoformat()